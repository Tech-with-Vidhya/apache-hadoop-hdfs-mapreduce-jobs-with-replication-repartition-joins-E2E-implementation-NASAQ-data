# hadoop-hdfs-mapreduce-jobs-with-replication-repartition-joins-E2E-implementation-NASAQ-data

This project is delivered as part of my Masters in Big Data Science (MSc BDS) Program for the module named “Big Data Processing” in Queen Mary University of London (QMUL), London, United Kingdom.  

This project includes the development of a MapReduce python script with and without combiner from scratch for the implementation of the various replication and repartition join strategies; for a big data job for the “NASDAQ” private dataset; listed with the NASDAQ daily stock variations between 1970 and 2010.   

The data files are stored in the Hadoop HDFS and 2 jobs are executed in the Hadoop Cluster.   

Identified solutions to the questions namely: 
1. Companies with most entries in the top 10 
2. Decision on appropriate join strategy to be used and implemented for this problem statement 
3. Year with the highest number of movements in the ‘Technology‘ sector 
4. List of companies that grew the most per year with its corresponding growth percentage using Top 10 algorithm  

**NOTE:** Due to the data privacy and the data protection policy to be adhered by the students; the datasets and the solution related code are not exposed and updated in the GitHub public profile; in order to be compliant with the Queen Mary University of London (QMUL) policies.
